{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5640832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d9217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c8a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 20\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "# image_height, image_width = 256, 256\n",
    "# image_height, image_width = 128, 128\n",
    "image_height, image_width = 64, 64\n",
    "\n",
    "dataset_directory = 'datasets/activity_dataset_v3'\n",
    "classes_list = [\"normal\", \"suspicious\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469cdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    # Empty List declared to store video frames\n",
    "    frames_list = []\n",
    "     \n",
    "    # Reading the Video File Using the VideoCapture\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1) \n",
    " \n",
    "    # Iterating through Video Frames\n",
    "    for fram_counter in range(SEQUENCE_LENGTH):\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES , fram_counter * skip_frames_window)\n",
    "        \n",
    "        success, frame = video_reader.read() \n",
    "        \n",
    "        if not success:\n",
    "            break\n",
    " \n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "         \n",
    "        normalized_frame = resized_frame / 255\n",
    "         \n",
    "        frames_list.append(normalized_frame)\n",
    "      \n",
    "    video_reader.release()\n",
    " \n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f74d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(train_test_path):\n",
    "    '''\n",
    "    It will extract the data of selected classes and create a dataset:-\n",
    "    \n",
    "    features:         list of extracted frames of videos\n",
    "    labels:           list of classes of those videos\n",
    "    video_file_path:  A list containing paths of video files in disl\n",
    "    '''\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_file_paths = []\n",
    "     \n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "         \n",
    "        files_list = os.listdir(os.path.join(dataset_directory + train_test_path, class_name))\n",
    " \n",
    "        for file_name in files_list:\n",
    " \n",
    "            video_file_path = os.path.join(dataset_directory + train_test_path, class_name, file_name)\n",
    " \n",
    "            frames = frames_extraction(video_file_path)\n",
    "            \n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_file_paths.append(video_file_path)\n",
    " \n",
    "    # Converting the features and labels lists to numpy arrays\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    " \n",
    "    return features, labels, video_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7669394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: normal\n",
      "Extracting Data of Class: suspicious\n"
     ]
    }
   ],
   "source": [
    "features_train, label_train, video_file_paths = create_dataset('/training_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a1b922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: normal\n",
      "Extracting Data of Class: suspicious\n"
     ]
    }
   ],
   "source": [
    "features_test, label_test, video_file_paths = create_dataset('/testing_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ddaae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encoded_labels_train = to_categorical(label_train)\n",
    "hot_encoded_labels_test = to_categorical(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8634cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_encoded_labels_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28ceba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 20, 64, 64, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1421916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train, features_test, labels_train, labels_test = train_test_split(features, hot_encoded_labels,test_size=0.25, shuffle=True, random_state= seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f29a674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = np.concatenate((features_test, hot_encoded_labels_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c8fa0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(): # LNRC Model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer: 1\n",
    "    model.add(TimeDistributed(Conv2D(filters = 16, kernel_size = 3,padding='same', activation = 'relu'), input_shape = (SEQUENCE_LENGTH,image_height, image_width, 3)))\n",
    "    model.add(TimeDistributed(MaxPool2D(4,4)))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "#     # Layer: 2\n",
    "#     model.add(TimeDistributed(Conv2D(filters= 16, kernel_size=3, padding='same', activation='relu')))\n",
    "#     model.add(TimeDistributed(MaxPool2D(4,4)))\n",
    "#     model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    # Layer: 3\n",
    "    model.add(TimeDistributed(Conv2D(filters= 32, kernel_size=3,padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPool2D(2,2)))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    \n",
    "    # Layer: 3\n",
    "    model.add(TimeDistributed(Conv2D(filters= 64, kernel_size=3,padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPool2D(2,2)))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    # Layer: 4\n",
    "    model.add(TimeDistributed(Conv2D(filters= 128, kernel_size=3, padding='same',activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPool2D(2,2)))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    # Flatten Layer\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    \n",
    "    # Connecting to LSTM\n",
    "    model.add(LSTM(32))\n",
    "    \n",
    "    # Final Classification Layer\n",
    "    model.add(Dense(len(classes_list), activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b4253bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer - 1\n",
    "    model.add(ConvLSTM2D(filters = 16, kernel_size = 3, activation = 'relu' ,data_format='channels_last', recurrent_dropout=0.2, return_sequences=True,  input_shape = (SEQUENCE_LENGTH,image_height, image_width, 3)))\n",
    "    model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    # Layer - 1\n",
    "    model.add(ConvLSTM2D(filters = 32, kernel_size = 3, activation = 'relu' ,data_format='channels_last', recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    # Layer - 1\n",
    "    model.add(ConvLSTM2D(filters = 64, kernel_size = 3, activation = 'relu' ,data_format='channels_last', recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "        \n",
    "    # Layer - 1\n",
    "    model.add(ConvLSTM2D(filters = 128, kernel_size = 3, activation = 'relu' ,data_format='channels_last', recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n",
    "    \n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Final Layer\n",
    "    model.add(Dense(len(classes_list) , activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ed23544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_14 (TimeDi  (None, 20, 64, 64, 16)   448       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 20, 16, 16, 16)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, 20, 16, 16, 16)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_17 (TimeDi  (None, 20, 16, 16, 32)   4640      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_18 (TimeDi  (None, 20, 8, 8, 32)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_19 (TimeDi  (None, 20, 8, 8, 32)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_20 (TimeDi  (None, 20, 8, 8, 64)     18496     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_21 (TimeDi  (None, 20, 4, 4, 64)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 20, 4, 4, 64)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_23 (TimeDi  (None, 20, 4, 4, 128)    73856     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_24 (TimeDi  (None, 20, 2, 2, 128)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_25 (TimeDi  (None, 20, 2, 2, 128)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_26 (TimeDi  (None, 20, 512)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                69760     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,266\n",
      "Trainable params: 167,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb3d8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model plot\n",
    "# plot_model(model, to_file='cnn_lstm_model.png', show_shapes=True, show_layer_names=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05f984c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7190 - accuracy: 0.5191WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 7s 1s/step - loss: 0.7190 - accuracy: 0.5191\n",
      "Epoch 2/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.6170WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6775 - accuracy: 0.6170\n",
      "Epoch 3/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6398 - accuracy: 0.6170WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6398 - accuracy: 0.6170\n",
      "Epoch 4/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.6170WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6262 - accuracy: 0.6170\n",
      "Epoch 5/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.6723WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5818 - accuracy: 0.6723\n",
      "Epoch 6/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.7362WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4942 - accuracy: 0.7362\n",
      "Epoch 7/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.7915WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4326 - accuracy: 0.7915\n",
      "Epoch 8/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.7830WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4000 - accuracy: 0.7830\n",
      "Epoch 9/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.7787WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4029 - accuracy: 0.7787\n",
      "Epoch 10/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.7574WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4323 - accuracy: 0.7574\n",
      "Epoch 11/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.7787WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4150 - accuracy: 0.7787\n",
      "Epoch 12/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.8170WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3997 - accuracy: 0.8170\n",
      "Epoch 13/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3499 - accuracy: 0.8511WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3499 - accuracy: 0.8511\n",
      "Epoch 14/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8511WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3550 - accuracy: 0.8511\n",
      "Epoch 15/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.8511WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3315 - accuracy: 0.8511\n",
      "Epoch 16/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.8638WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3122 - accuracy: 0.8638\n",
      "Epoch 17/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.8723WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2975 - accuracy: 0.8723\n",
      "Epoch 18/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.8979WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2500 - accuracy: 0.8979\n",
      "Epoch 19/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9064WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2276 - accuracy: 0.9064\n",
      "Epoch 20/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9234WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1953 - accuracy: 0.9234\n",
      "Epoch 21/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9191WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1990 - accuracy: 0.9191\n",
      "Epoch 22/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.9745WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1183 - accuracy: 0.9745\n",
      "Epoch 23/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9532WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1325 - accuracy: 0.9532\n",
      "Epoch 24/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9745WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0992 - accuracy: 0.9745\n",
      "Epoch 25/25\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9745WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0830 - accuracy: 0.9745\n"
     ]
    }
   ],
   "source": [
    "# Adding Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "# Adding loss, optimizer and metrics values to the model.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])\n",
    " \n",
    "# Start Training\n",
    "model_training_history = model.fit(x = features_train, y = hot_encoded_labels_train, epochs = epochs,validation_split = 0.2, batch_size = batch_size, shuffle = True, callbacks = [early_stopping_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72ff4e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 655ms/step - loss: 0.0538 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_evaluation_history = model.evaluate(features_test, hot_encoded_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64b41979",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/cnn_lstm_64_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa5ca1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
    "  # Get Metric values using metric names as identifiers\n",
    "  metric_value_1 = model_training_history.history[metric_name_1]\n",
    "  metric_value_2 = model_training_history.history[metric_name_2]\n",
    " \n",
    "  # Constructing a range object which will be used as time \n",
    "  epochs = range(len(metric_value_1))\n",
    "   \n",
    "  # Plotting the Graph\n",
    "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "   \n",
    "  # Adding title to the plot\n",
    "  plt.title(str(plot_name))\n",
    " \n",
    "  # Adding legend to the plot\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03bce58d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# loss graph\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Loss vs Total Validation Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mplot_metric\u001b[1;34m(metric_name_1, metric_name_2, plot_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_metric\u001b[39m(metric_name_1, metric_name_2, plot_name):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m# Get Metric values using metric names as identifiers\u001b[39;00m\n\u001b[0;32m      3\u001b[0m   metric_value_1 \u001b[38;5;241m=\u001b[39m model_training_history\u001b[38;5;241m.\u001b[39mhistory[metric_name_1]\n\u001b[1;32m----> 4\u001b[0m   metric_value_2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_training_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_name_2\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;66;03m# Constructing a range object which will be used as time \u001b[39;00m\n\u001b[0;32m      7\u001b[0m   epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(metric_value_1))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "# loss graph\n",
    "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cae9ee4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# accuracy graph\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Accuracy vs Total Validation Accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mplot_metric\u001b[1;34m(metric_name_1, metric_name_2, plot_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_metric\u001b[39m(metric_name_1, metric_name_2, plot_name):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m# Get Metric values using metric names as identifiers\u001b[39;00m\n\u001b[0;32m      3\u001b[0m   metric_value_1 \u001b[38;5;241m=\u001b[39m model_training_history\u001b[38;5;241m.\u001b[39mhistory[metric_name_1]\n\u001b[1;32m----> 4\u001b[0m   metric_value_2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_training_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_name_2\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;66;03m# Constructing a range object which will be used as time \u001b[39;00m\n\u001b[0;32m      7\u001b[0m   epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(metric_value_1))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "# accuracy graph\n",
    "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e00632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/LNRC_MODEL_128_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef884098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_video(video_file_path, output_file_path, SEQUENCE_LENGTH):\n",
    "     \n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "    \n",
    "    orignal_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    orignal_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'),\n",
    "                                 video_reader.get(cv2.CAP_PROP_FPS), (orignal_video_width, orignal_video_height))\n",
    "    \n",
    "    frames_queue = deque(maxlen = SEQUENCE_LENGTH)\n",
    "    predictions= []\n",
    "    \n",
    "    predicted_class_name = ''\n",
    "    \n",
    "    while video_reader.isOpened():\n",
    "        ok , frame = video_reader.read()\n",
    "        cv2.imshow('fram',frame)\n",
    "        \n",
    "        if not ok:\n",
    "            break\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # taking keyboard input 'q' to brake it\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        frames_queue.append(normalized_frame)\n",
    "        \n",
    "        if len(frames_queue) == SEQUENCE_LENGTH:\n",
    "            predicted_label_probabilities = model.predict(np.expand_dims(frames_queue, axis=0))[0]\n",
    "            predicted_label = np.argmax(predicted_label_probabilities)\n",
    "            \n",
    "            predictions.append(predicted_label)\n",
    "            predicted_class_name = classes_list[predicted_label]\n",
    "        \n",
    "            print(predicted_class_name)\n",
    "            \n",
    "            if(predicted_class_name == 'normal'):\n",
    "                cv2.putText(frame, f'Activity: {predicted_class_name}', (0, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "            elif(predicted_class_name == 'suspicious'):\n",
    "                cv2.putText(frame, f'Activity: {predicted_class_name}', (0, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            \n",
    "            \n",
    "        \n",
    "        video_writer.write(frame)\n",
    "        \n",
    "        \n",
    "        \n",
    "    video_reader.release()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e3ee0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_on_video('testing_data/fight.mp4', 'testing_data/result.mp4', SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8dba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
